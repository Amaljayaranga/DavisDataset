{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DavisDatasetNew.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdfdbiQLqtgBBNL48rKC9M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amaljayaranga/DavisDataset/blob/master/DavisDatasetNew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e-vZVvJdmMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "\n",
        "class DavisDataset(Dataset):\n",
        "\n",
        "    def __init__(self, memmap, json_data, need_classes):\n",
        "\n",
        "        ##cropping objects from memaps and add to idxes\n",
        "        self.memmap = memmap\n",
        "        self.json_data = json_data\n",
        "        self.idxes = {}\n",
        "        self.need_classes = need_classes\n",
        "\n",
        "        imgs = self.json_data['imgs']\n",
        "        for img_index, img in enumerate(imgs):\n",
        "            idx = int(img['index'])\n",
        "            classes = img['objects']\n",
        "            classes_ = []\n",
        "            objects_ = []\n",
        "            class_objects = []\n",
        "            for class_idx, class_ in enumerate(classes):\n",
        "               if class_['class']  in self.need_classes:\n",
        "                  single_class = class_['class']\n",
        "                  x = class_['x']\n",
        "                  y = class_['y']\n",
        "                  width = class_['width']\n",
        "                  height = class_['height']\n",
        "\n",
        "                  image = self.memmap[img_index]\n",
        "                  \n",
        "                  crop_img = image[y:y + height, x:x + width]\n",
        "                  #img_resized = cv2.resize(crop_img, (200,200), interpolation = cv2.INTER_AREA)\n",
        "                  classes_.append(single_class)\n",
        "                  #objects_.append(self.image_to_tensor(img_resized))\n",
        "                  objects_.append(crop_img)\n",
        "\n",
        "            class_objects.append(classes_)\n",
        "            class_objects.append(objects_)\n",
        "            self.idxes[idx] = class_objects\n",
        "\n",
        "    def image_to_tensor(self,image, mean=0, std=1.):\n",
        "        image = image.astype(np.float32)\n",
        "        image = (image - mean) / std\n",
        "        image = image.transpose((2, 0, 1))\n",
        "        tensor = torch.from_numpy(image)\n",
        "        return tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memmap)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        classes, images = self.idxes.get(index)\n",
        "        return [classes, images]\n",
        "\n",
        "\n",
        "\n",
        "#loading memmap and json for same context\n",
        "folder_path='./drive/My Drive/Thesis_2020/'\n",
        "complete_shape=(60,480,854,3)\n",
        "complete_memmap = folder_path+'people-horse.mmap'\n",
        "newfp = np.memmap(complete_memmap, dtype='uint8', mode='r', shape=complete_shape)\n",
        "#loading json\n",
        "with open(folder_path+'people-horse-json.txt') as json_file:\n",
        "    data_json = json.load(json_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def show_objects(classes,images):\n",
        "  img_np = []\n",
        "  for i in range(len(classes)):\n",
        "    img_np_i = np.asarray(images[i])\n",
        "    img_np.append(img_np_i)\n",
        "\n",
        "  f, axarr = plt.subplots(1, len(classes))\n",
        "  for i in range(len(classes)):\n",
        "    axarr[i].imshow(img_np[i], interpolation='nearest')\n",
        "  plt.show()\n",
        "\n",
        "need_classes = ['person','horse']\n",
        "same_conext_ds = DavisDataset(newfp, data_json, need_classes)\n",
        "\n",
        "\n",
        "def show_images(same_conext_ds):\n",
        "  for i in range(60):\n",
        "    classes, images  = same_conext_ds.__getitem__(i)\n",
        "    show_objects(classes,images)\n",
        "\n",
        "show_images(same_conext_ds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}